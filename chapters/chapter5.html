<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chapter 5: Large Language Models | AI Tutorial</title>
    <link rel="stylesheet" href="../assets/css/style.css">
    <link rel="stylesheet" href="../assets/css/theme.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
</head>
<body>
    <div class="site-wrapper">
        <header class="site-header">
            <div class="header-content">
                <div class="site-logo"><h1><a href="../index.html">AI <span>Tutorial</span></a></h1></div>
                <nav class="main-nav">
                    <ul>
                        <li><a href="../index.html">Home</a></li>
                        <li><a href="chapter1.html" class="active">Chapters</a></li>
                        <li><a href="chapter15.html">Glossary</a></li>
                        <li><button id="theme-toggle" class="theme-toggle">üåô</button></li>
                    </ul>
                </nav>
                <button id="mobile-menu-toggle" class="mobile-menu-toggle">‚ò∞</button>
            </div>
        </header>

        <div class="content-wrapper">
            <aside class="sidebar">
                <h3>Chapters</h3>
                <ul class="toc-list">
                    <li><a href="../index.html">üè† Home</a></li>
                    <li><a href="chapter1.html">Ch 1: AI Foundations</a></li>
                    <li><a href="chapter2.html">Ch 2: Machine Learning</a></li>
                    <li><a href="chapter3.html">Ch 3: Deep Learning</a></li>
                    <li><a href="chapter4.html">Ch 4: Transformers</a></li>
                    <li><a href="chapter5.html" class="active">Ch 5: LLMs</a></li>
                    <li><a href="chapter6.html">Ch 6: Generative AI</a></li>
                    <li><a href="chapter7.html">Ch 7: Embeddings</a></li>
                    <li><a href="chapter8.html">Ch 8: RAG</a></li>
                    <li><a href="chapter9.html">Ch 9: Fine-Tuning</a></li>
                    <li><a href="chapter10.html">Ch 10: Multimodal AI</a></li>
                    <li><a href="chapter11.html">Ch 11: Agents & MCP</a></li>
                    <li><a href="chapter12.html">Ch 12: Tooling</a></li>
                    <li><a href="chapter13.html">Ch 13: Infrastructure</a></li>
                    <li><a href="chapter14.html">Ch 14: System Design</a></li>
                    <li><a href="chapter15.html">Ch 15: Glossary</a></li>
                </ul>
            </aside>

            <main class="main-content">
                <h1>Chapter 5: Large Language Models (LLMs)</h1>
                
                <p class="chapter-intro">
                    Large Language Models represent the current frontier of AI, demonstrating remarkable abilities 
                    in language understanding, generation, reasoning, and few-shot learning. This chapter explores 
                    the GPT series, scaling laws, emergent abilities, and the engineering behind billion-parameter models.
                </p>

                <h2>What are Large Language Models?</h2>
                
                <p>
                    LLMs are neural networks with billions of parameters trained on massive text corpora to predict 
                    the next token in a sequence. Through this seemingly simple objective, they develop sophisticated 
                    capabilities including:
                </p>
                <ul>
                    <li>Natural language understanding and generation</li>
                    <li>Code synthesis and debugging</li>
                    <li>Logical reasoning and problem solving</li>
                    <li>Few-shot and zero-shot task adaptation</li>
                    <li>In-context learning without weight updates</li>
                </ul>

                <div class="diagram-container">
                    <div class="diagram-title">LLM Evolution Timeline</div>
                    <pre class="mermaid">
timeline
    title Major LLM Milestones
    2018 : BERT (340M params)<br/>GPT-1 (117M params)
    2019 : GPT-2 (1.5B params)<br/>T5 (11B params)
    2020 : GPT-3 (175B params)
    2021 : Jurassic-1 (178B)<br/>Gopher (280B)
    2022 : PaLM (540B)<br/>OPT (175B)<br/>BLOOM (176B)
    2022-2023 : ChatGPT<br/>GPT-4<br/>Claude<br/>Gemini
    2024-2025 : GPT-4 Turbo<br/>Claude 3<br/>Gemini 1.5 Pro
                    </pre>
                </div>

                <h2>The GPT Family</h2>

                <h3>GPT-1 (2018) - Proof of Concept</h3>
                <ul>
                    <li><strong>Parameters:</strong> 117 million</li>
                    <li><strong>Innovation:</strong> Demonstrated pre-training + fine-tuning paradigm</li>
                    <li><strong>Architecture:</strong> 12-layer decoder-only Transformer</li>
                    <li><strong>Training:</strong> BookCorpus (7,000 books)</li>
                </ul>

                <h3>GPT-2 (2019) - Scale Brings Capabilities</h3>
                <ul>
                    <li><strong>Parameters:</strong> 1.5 billion (largest variant)</li>
                    <li><strong>Innovation:</strong> Zero-shot task performance without fine-tuning</li>
                    <li><strong>Training:</strong> WebText (40GB of internet text)</li>
                    <li><strong>Controversy:</strong> Initially withheld due to misuse concerns</li>
                </ul>

                <h3>GPT-3 (2020) - The Breakthrough</h3>
                <ul>
                    <li><strong>Parameters:</strong> 175 billion</li>
                    <li><strong>Innovation:</strong> Few-shot in-context learning</li>
                    <li><strong>Training:</strong> 570GB text, 300 billion tokens</li>
                    <li><strong>Compute:</strong> ~3640 petaflop/s-days</li>
                    <li><strong>Impact:</strong> Enabled conversational AI, code generation, creative writing</li>
                </ul>

                <h3>ChatGPT (2022) - Mass Adoption</h3>
                <ul>
                    <li><strong>Base:</strong> GPT-3.5 with RLHF (Reinforcement Learning from Human Feedback)</li>
                    <li><strong>Innovation:</strong> Instruction following, conversational interface</li>
                    <li><strong>Training:</strong> Supervised fine-tuning ‚Üí reward model ‚Üí PPO optimization</li>
                    <li><strong>Impact:</strong> 100M users in 2 months (fastest-growing app in history)</li>
                </ul>

                <h3>GPT-4 (2023) - Multimodal Reasoning</h3>
                <ul>
                    <li><strong>Capabilities:</strong> Text + image inputs, advanced reasoning</li>
                    <li><strong>Performance:</strong> Passes bar exam (90th percentile)</li>
                    <li><strong>Context:</strong> 8K-32K tokens (extended to 128K)</li>
                    <li><strong>Safety:</strong> Extensive red-teaming and alignment work</li>
                </ul>

                <div class="deep-dive">
                    <div class="deep-dive-header">
                        <span>üî¨ Deep Dive: Scaling Laws</span>
                        <span class="deep-dive-icon">‚ñº</span>
                    </div>
                    <div class="deep-dive-content">
                        <div class="deep-dive-inner">
                            <h3>The Power Law of AI</h3>
                            <p>
                                Research by OpenAI, DeepMind, and others has revealed predictable relationships 
                                between model performance and three factors:
                            </p>
                            
                            <h4>Key Variables</h4>
                            <ul>
                                <li><strong>N (Model Size):</strong> Number of parameters</li>
                                <li><strong>D (Dataset Size):</strong> Number of training tokens</li>
                                <li><strong>C (Compute Budget):</strong> Total FLOPs for training</li>
                            </ul>
                            
                            <h4>Scaling Law Equation</h4>
                            <pre><code>Loss ‚àù N^(-Œ±) √ó D^(-Œ≤) √ó C^(-Œ≥)

Typical values:
Œ± ‚âà 0.076 (model size)
Œ≤ ‚âà 0.095 (dataset size)
Œ≥ ‚âà 0.050 (compute)
</code></pre>
                            
                            <h4>Key Insights</h4>
                            <ul>
                                <li>Performance improves smoothly and predictably with scale</li>
                                <li>Model size and data size should grow proportionally</li>
                                <li>There's no evidence of hitting a ceiling yet</li>
                                <li>Compute-optimal training balances model size and data</li>
                            </ul>
                            
                            <h4>Chinchilla Scaling Laws (2022)</h4>
                            <p>
                                DeepMind's research showed previous models were under-trained:
                            </p>
                            <ul>
                                <li>For a given compute budget, smaller models trained on more data perform better</li>
                                <li>Optimal ratio: ~20 tokens per parameter</li>
                                <li>Chinchilla (70B params) outperformed Gopher (280B params) with less compute</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <h2>Emergent Abilities</h2>
                
                <p>
                    As LLMs scale, they develop capabilities not explicitly trained for‚Äîabilities that "emerge" 
                    at certain scale thresholds.
                </p>

                <h3>Examples of Emergent Abilities</h3>
                <ul>
                    <li><strong>Chain-of-Thought Reasoning:</strong> Breaking problems into steps</li>
                    <li><strong>Few-Shot Learning:</strong> Learning from handful of examples</li>
                    <li><strong>Instruction Following:</strong> Understanding and executing complex instructions</li>
                    <li><strong>Code Generation:</strong> Writing functional programs from descriptions</li>
                    <li><strong>Multilingual Transfer:</strong> Performance in low-resource languages</li>
                    <li><strong>Mathematical Reasoning:</strong> Solving word problems and equations</li>
                </ul>

                <div class="callout callout-note">
                    <div class="callout-title">üí° The Scaling Hypothesis</div>
                    <p>
                        Many AI researchers believe that scaling compute, data, and parameters is the primary path 
                        to more capable AI. Others argue architectural innovations and data quality matter more.
                    </p>
                </div>

                <h2>Training Large Language Models</h2>

                <h3>Pre-Training Phase</h3>
                <ol>
                    <li><strong>Data Collection:</strong> Scrape web text, books, code repositories</li>
                    <li><strong>Data Filtering:</strong> Remove low-quality, toxic, or copyrighted content</li>
                    <li><strong>Tokenization:</strong> Convert text to tokens (typically BPE or SentencePiece)</li>
                    <li><strong>Training Objective:</strong> Next-token prediction with cross-entropy loss</li>
                    <li><strong>Distributed Training:</strong> Parallelize across thousands of GPUs/TPUs</li>
                </ol>

                <h3>Post-Training Alignment</h3>

                <div class="diagram-container">
                    <div class="diagram-title">RLHF Pipeline</div>
                    <pre class="mermaid">
graph TD
                        A[Base LLM<br/>Pre-trained] --> B[Supervised Fine-Tuning<br/>SFT]
    B --> C[Reward Model<br/>Training]
    C --> D[RL Optimization<br/>PPO]
    D --> E[Aligned LLM<br/>ChatGPT-like]
    
    F[Human Demonstrations] --> B
    G[Human Preferences] --> C
    
    style A fill:#4d94ff,stroke:#333,stroke-width:2px,color:#fff
    style E fill:#28a745,stroke:#333,stroke-width:2px,color:#fff
                    </pre>
                </div>

                <h4>Step 1: Supervised Fine-Tuning (SFT)</h4>
                <ul>
                    <li>Human labelers demonstrate desired outputs</li>
                    <li>Model learns to follow instructions</li>
                    <li>Typically uses 10K-100K examples</li>
                </ul>

                <h4>Step 2: Reward Modeling</h4>
                <ul>
                    <li>Collect human preferences between outputs</li>
                    <li>Train reward model to predict human ratings</li>
                    <li>Reward model guides RL optimization</li>
                </ul>

                <h4>Step 3: Reinforcement Learning</h4>
                <ul>
                    <li>Use PPO to optimize policy against reward model</li>
                    <li>Balance maximizing reward with staying close to SFT model (KL penalty)</li>
                    <li>Iterative process with multiple rounds</li>
                </ul>

                <h2>Prompt Engineering</h2>
                
                <p>
                    The art and science of crafting inputs to elicit desired outputs from LLMs.
                </p>

                <h3>Core Techniques</h3>

                <h4>1. Zero-Shot Prompting</h4>
                <pre><code>Prompt: "Translate to French: Hello, how are you?"
Output: "Bonjour, comment allez-vous?"
</code></pre>

                <h4>2. Few-Shot Prompting</h4>
                <pre><code>Prompt: 
"Q: What is the capital of France? A: Paris
Q: What is the capital of Germany? A: Berlin
Q: What is the capital of Italy? A:"

Output: "Rome"
</code></pre>

                <h4>3. Chain-of-Thought (CoT)</h4>
                <pre><code>Prompt: "Roger has 5 tennis balls. He buys 2 more cans 
of tennis balls. Each can has 3 balls. How many tennis 
balls does he have now? Let's think step by step."

Output:
"1. Roger starts with 5 balls
2. He buys 2 cans
3. Each can has 3 balls, so 2 √ó 3 = 6 balls
4. Total: 5 + 6 = 11 balls"
</code></pre>

                <h4>4. Role Prompting</h4>
                <pre><code>Prompt: "You are an expert Python developer. Write 
a function to calculate fibonacci numbers."
</code></pre>

                <h3>Advanced Techniques</h3>
                <ul>
                    <li><strong>Self-Consistency:</strong> Sample multiple reasoning paths, take majority vote</li>
                    <li><strong>Tree of Thoughts:</strong> Explore multiple reasoning branches</li>
                    <li><strong>ReAct:</strong> Interleave reasoning and acting with tools</li>
                    <li><strong>AutoGPT:</strong> Break tasks into subtasks autonomously</li>
                </ul>

                <div class="callout callout-warning">
                    <div class="callout-title">‚ö†Ô∏è Prompt Sensitivity</div>
                    <p>
                        LLMs can be highly sensitive to prompt wording. Small changes can dramatically affect output 
                        quality. Systematic prompt engineering and testing is essential for production systems.
                    </p>
                </div>

                <h2>Limitations and Challenges</h2>

                <h3>Known Issues</h3>
                <ul>
                    <li><strong>Hallucinations:</strong> Generating plausible but false information</li>
                    <li><strong>Lack of Grounding:</strong> No direct connection to real-world knowledge</li>
                    <li><strong>Inconsistency:</strong> Different answers to semantically identical questions</li>
                    <li><strong>Bias:</strong> Reflecting and amplifying training data biases</li>
                    <li><strong>Context Window:</strong> Limited memory (though expanding rapidly)</li>
                    <li><strong>Computational Cost:</strong> Expensive inference at scale</li>
                    <li><strong>Reasoning Limitations:</strong> Struggle with multi-step logic and math</li>
                </ul>

                <h3>Safety Concerns</h3>
                <ul>
                    <li>Generating harmful content (misinformation, hate speech)</li>
                    <li>Privacy violations (regurgitating training data)</li>
                    <li>Jailbreaking attempts to bypass safety guardrails</li>
                    <li>Dual-use potential (deepfakes, social engineering)</li>
                </ul>

                <h2>Open Source vs. Closed Models</h2>

                <table>
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th>Organization</th>
                            <th>Access</th>
                            <th>Parameters</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>GPT-4</strong></td>
                            <td>OpenAI</td>
                            <td>API only</td>
                            <td>Undisclosed</td>
                        </tr>
                        <tr>
                            <td><strong>Claude</strong></td>
                            <td>Anthropic</td>
                            <td>API only</td>
                            <td>Undisclosed</td>
                        </tr>
                        <tr>
                            <td><strong>Gemini</strong></td>
                            <td>Google</td>
                            <td>API only</td>
                            <td>Undisclosed</td>
                        </tr>
                        <tr>
                            <td><strong>LLaMA 2</strong></td>
                            <td>Meta</td>
                            <td>Open weights</td>
                            <td>7B-70B</td>
                        </tr>
                        <tr>
                            <td><strong>Mistral</strong></td>
                            <td>Mistral AI</td>
                            <td>Open weights</td>
                            <td>7B-8x7B</td>
                        </tr>
                        <tr>
                            <td><strong>BLOOM</strong></td>
                            <td>BigScience</td>
                            <td>Fully open</td>
                            <td>176B</td>
                        </tr>
                    </tbody>
                </table>

                <div class="key-terms">
                    <h3>Key Terms</h3>
                    <dl>
                        <dt>Large Language Model (LLM)</dt>
                        <dd>Neural network with billions of parameters trained on massive text corpora</dd>
                        
                        <dt>Pre-training</dt>
                        <dd>Initial training phase on large unlabeled corpus using next-token prediction</dd>
                        
                        <dt>RLHF</dt>
                        <dd>Reinforcement Learning from Human Feedback; aligning LLMs with human preferences</dd>
                        
                        <dt>Prompt Engineering</dt>
                        <dd>Crafting effective inputs to elicit desired LLM outputs</dd>
                        
                        <dt>Chain-of-Thought</dt>
                        <dd>Prompting technique that encourages step-by-step reasoning</dd>
                        
                        <dt>Emergent Abilities</dt>
                        <dd>Capabilities that appear at certain scale thresholds, not explicitly trained</dd>
                        
                        <dt>Hallucination</dt>
                        <dd>LLM generating plausible but factually incorrect information</dd>
                        
                        <dt>Context Window</dt>
                        <dd>Maximum number of tokens an LLM can process at once</dd>
                    </dl>
                </div>

                <div class="review-questions">
                    <h3>Review Questions</h3>
                    <ol>
                        <li>How do scaling laws predict LLM performance?</li>
                        <li>What are emergent abilities and why are they significant?</li>
                        <li>Explain the three stages of RLHF training.</li>
                        <li>What is the difference between zero-shot and few-shot prompting?</li>
                        <li>Why do LLMs hallucinate and how can it be mitigated?</li>
                        <li>Compare the advantages of open vs. closed LLMs.</li>
                        <li>How does chain-of-thought prompting improve reasoning?</li>
                    </ol>
                </div>

                <div class="exercises">
                    <h3>Practical Exercises</h3>
                    <ol>
                        <li><strong>Prompt Comparison:</strong> Test same task with zero-shot, few-shot, and CoT prompts. Compare outputs.</li>
                        <li><strong>API Integration:</strong> Build simple application using OpenAI or Anthropic API with error handling.</li>
                        <li><strong>Prompt Engineering:</strong> Design prompts for 5 different tasks. Document what works and what doesn't.</li>
                        <li><strong>Bias Analysis:</strong> Probe an LLM for biases across different demographics. Document findings.</li>
                    </ol>
                </div>

                <div class="chapter-navigation">
                    <a href="chapter4.html" class="nav-button prev">‚Üê Chapter 4: Transformers</a>
                    <a href="chapter6.html" class="nav-button next">Next: Generative AI ‚Üí</a>
                </div>

            </main>
        </div>

        <footer class="site-footer"><p>&copy; 2025 AI Tutorial For Everyone</p></footer>
    </div>

    <div id="ai-chat-widget-placeholder"></div>
    <script src="../assets/js/darkmode.js"></script>
    <script src="../assets/js/nav.js"></script>
    <script src="../assets/js/main.js"></script>
</body>
</html>
