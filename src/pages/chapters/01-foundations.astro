---
import BaseLayout from '../../layouts/BaseLayout.astro';
---

<BaseLayout 
  title="Chapter 1: Foundations of Artificial Intelligence" 
  description="Explore the history, core concepts, and fundamental principles of AI"
  currentPage="/chapters/01-foundations"
>
  <article class="chapter-content">
    <h1>Chapter 1: Foundations of Artificial Intelligence</h1>
    
    <div class="callout info">
      <div class="callout-title">üìö What You'll Learn</div>
      <ul>
        <li>The history and evolution of AI</li>
        <li>Core AI paradigms and approaches</li>
        <li>Search algorithms and problem-solving</li>
        <li>Knowledge representation methods</li>
        <li>The philosophical foundations of AI</li>
      </ul>
    </div>

    <h2>1.1 What is Artificial Intelligence?</h2>
    
    <p>
      <strong>Artificial Intelligence (AI)</strong> is the science and engineering of creating intelligent 
      machines that can perform tasks typically requiring human intelligence. These tasks include visual 
      perception, speech recognition, decision-making, language translation, and problem-solving.
    </p>

    <h3>Defining Intelligence</h3>
    
    <p>
      Intelligence manifests in multiple forms. AI researchers typically focus on computational intelligence‚Äîthe 
      ability to acquire, process, and apply knowledge to solve problems. Modern AI systems demonstrate these capabilities:
    </p>

    <ul>
      <li><strong>Reasoning:</strong> Drawing logical conclusions from available information (e.g., GPT-4 passing the bar exam with human-level scores)</li>
      <li><strong>Learning:</strong> Improving performance through experience (e.g., AlphaGo Zero learning chess from self-play alone)</li>
      <li><strong>Perception:</strong> Interpreting sensory data (e.g., computer vision models achieving >99% accuracy on ImageNet)</li>
      <li><strong>Language Processing:</strong> Understanding and generating natural language (e.g., modern LLMs producing coherent, contextual responses)</li>
      <li><strong>Problem Solving:</strong> Finding solutions to complex challenges (e.g., AlphaFold 2 solving protein folding in hours vs. months)</li>
      <li><strong>Creativity:</strong> Generating novel content across text, images, video, and audio (e.g., DALL-E, Midjourney, Sora)</li>
    </ul>

    <div class="callout info">
      <div class="callout-title">üí° Modern AI Capabilities</div>
      <p>
        As of 2025, AI systems have achieved remarkable milestones: passing professional exams (law, medicine), 
        creating original artwork, composing music, writing code, discovering new antibiotics, and assisting in 
        scientific research. The line between "AI" and "just software" continues to blur‚Äîmany capabilities once 
        considered AI are now simply expected features.
      </p>
    </div>

    <pre class="mermaid" set:html={`mindmap
  root((Artificial Intelligence))
    Reasoning
      Logic
      Inference
      Decision Making
    Learning
      Supervised
      Unsupervised
      Reinforcement
    Perception
      Computer Vision
      Speech Recognition
      Sensor Processing
    Language
      NLP
      Translation
      Generation
    Problem Solving
      Search
      Planning
      Optimization
      `} />

    <h3>The Turing Test</h3>
    
    <p>
      In 1950, Alan Turing proposed a practical test for machine intelligence: if a human evaluator cannot 
      reliably distinguish between a machine and a human through text-based conversation, the machine can be 
      said to exhibit intelligent behavior. While controversial, this test influenced decades of AI research.
    </p>

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üîç Deep Dive: Alternative Measures of Intelligence</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <p>
          Modern AI research has moved beyond the Turing Test to more nuanced measures:
        </p>
        <ul>
          <li><strong>Task-Specific Benchmarks:</strong> ImageNet for vision, MMLU/HELM for LLMs, HumanEval for code generation</li>
          <li><strong>General Intelligence Tests:</strong> ARC-AGI (Fran√ßois Chollet, 2019) - OpenAI o3 achieved 87.5%, surpassing the typical human score of 84% in 2024</li>
          <li><strong>Professional Competency:</strong> Bar exam, USMLE medical boards, AP exams - GPT-4 achieves human-level or better performance</li>
          <li><strong>Mathematical Reasoning:</strong> IMO (International Mathematical Olympiad) problems - Google's systems achieved gold medal standard in 2025</li>
          <li><strong>Efficiency Metrics:</strong> Performance relative to compute, data, and energy consumption</li>
          <li><strong>Robustness:</strong> Behavior under adversarial conditions, out-of-distribution generalization</li>
          <li><strong>Alignment & Safety:</strong> Following intended goals, avoiding harmful outputs, truthfulness</li>
          <li><strong>Scientific Discovery:</strong> Novel contributions to research (e.g., AlphaFold's protein structures, AI-discovered antibiotics)</li>
        </ul>
        <p>
          <em>Source: Fran√ßois Chollet states about ARC-AGI: "You'll know AGI is here when the exercise of creating 
          tasks that are easy for regular humans but hard for AI becomes simply impossible."</em>
        </p>
      </div>
    </div>

    <h2>1.2 History of AI</h2>

    <pre class="mermaid" set:html={`timeline
    title Evolution of Artificial Intelligence
    1950s : Birth of AI (Turing Test 1950, Dartmouth Conference 1956)
    1960s : Early Optimism (Expert Systems, ELIZA chatbot)
    1970s : First AI Winter (Lighthill Report 1973, funding cuts)
    1980s : Expert Systems Renaissance (Cyc knowledge base)
    1990s : Statistical Methods & Second AI Winter
    2000s : Big Data & Machine Learning Renaissance
    2010s : Deep Learning Revolution (AlexNet 2012, AlphaGo 2016)
    2017-2019 : Transformer Era (Attention Is All You Need, GPT-2)
    2020-2022 : LLM Breakthrough (GPT-3, ChatGPT launch Nov 2022)
    2023-2025 : AI Boom (GPT-4, Nobel Prizes, $500B+ investments)
      `} />

    <h3>Key Milestones</h3>

    <table>
      <thead>
        <tr>
          <th>Year</th>
          <th>Milestone</th>
          <th>Significance</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>1950</td>
          <td>Turing Test proposed</td>
          <td>Foundational concept for machine intelligence</td>
        </tr>
        <tr>
          <td>1956</td>
          <td>Dartmouth Conference</td>
          <td>AI officially becomes a field of study</td>
        </tr>
        <tr>
          <td>1997</td>
          <td>Deep Blue defeats Kasparov</td>
          <td>AI surpasses human chess champion</td>
        </tr>
        <tr>
          <td>2012</td>
          <td>AlexNet wins ImageNet</td>
          <td>Deep learning revolution begins</td>
        </tr>
        <tr>
          <td>2016</td>
          <td>AlphaGo defeats Lee Sedol</td>
          <td>AI masters Go, considered impossible</td>
        </tr>
        <tr>
          <td>2017</td>
          <td>Transformer architecture</td>
          <td>Foundation for modern LLMs</td>
        </tr>
        <tr>
          <td>2022</td>
          <td>ChatGPT release</td>
          <td>AI enters mainstream consciousness, fastest-growing app (100M users in 2 months)</td>
        </tr>
        <tr>
          <td>2023</td>
          <td>GPT-4 passes bar exam</td>
          <td>LLMs achieve human-level scores on professional tests</td>
        </tr>
        <tr>
          <td>2024</td>
          <td>Nobel Prizes for AI pioneers</td>
          <td>Hinton, Hopfield (Physics); Hassabis, Jumper, Baker (Chemistry)</td>
        </tr>
        <tr>
          <td>2024</td>
          <td>OpenAI o3 model</td>
          <td>87.5% on ARC-AGI benchmark, surpassing typical human score of 84%</td>
        </tr>
        <tr>
          <td>2025</td>
          <td>AI infrastructure boom</td>
          <td>$500B+ investment in AI data centers and computing infrastructure</td>
        </tr>
      </tbody>
    </table>

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üîç Deep Dive: The AI Winters</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <p>
          AI has experienced several "winters"‚Äîperiods of reduced funding and interest:
        </p>
        <h4>First AI Winter (1974-1980)</h4>
        <ul>
          <li>Limitations of perceptrons exposed by Minsky & Papert</li>
          <li>Failure to achieve early promises led to funding cuts</li>
          <li>Computational constraints limited practical applications</li>
        </ul>
        <h4>Second AI Winter (1987-1993)</h4>
        <ul>
          <li>Expert systems proved brittle and hard to maintain</li>
          <li>Market for specialized AI hardware collapsed</li>
          <li>Shift toward more statistical approaches</li>
        </ul>
        <p>
          These winters taught important lessons about managing expectations and the importance of 
          theoretical foundations backed by empirical success.
        </p>
      </div>
    </div>

    <h2>1.3 AI Paradigms</h2>

    <p>AI research has evolved through several distinct paradigms:</p>

    <h3>Symbolic AI (GOFAI - Good Old-Fashioned AI)</h3>
    
    <p>
      The earliest approach to AI, dominant from the 1950s through 1980s. Symbolic AI represents knowledge 
      using symbols and rules, manipulating them through logical inference.
    </p>

    <pre set:html={`<code># Example: Simple rule-based expert system
# Dominant AI paradigm 1960s-1980s, still used in specific domains (e.g., business rules)
rules = [
    ("IF animal has feathers THEN animal is bird", 0.9),
    ("IF animal is bird AND animal swims THEN animal is waterfowl", 0.95),
    ("IF animal is waterfowl AND animal is white THEN animal is swan", 0.8)
]

# Initial facts from observation
facts = {{"has feathers": True, "swims": True, "is white": True}}

def infer(rules, facts):
    """Forward chaining inference engine
    
    This approach works well for well-defined domains but struggles with:
    - Uncertainty and noisy data (addressed by probabilistic methods)
    - Learning from examples (neural networks excel here)
    - Common sense reasoning (still challenging as of 2025)
    
    Modern systems often combine symbolic reasoning with neural approaches.
    """
    inferred = facts.copy()
    changed = True
    while changed:
        changed = False
        for rule, confidence in rules:
            # Parse and evaluate rule (simplified)
            if evaluate_rule(rule, inferred):
                conclusion = extract_conclusion(rule)
                if conclusion not in inferred:
                    inferred[conclusion] = confidence
                    changed = True
    return inferred

# Example inference:
# Input: {{'has feathers': True, 'swims': True, 'is white': True}}
# Output: {{'has feathers': True, 'swims': True, 'is white': True, 
#          'is bird': 0.9, 'is waterfowl': 0.95, 'is swan': 0.8}}</code>`} />

    <div class="callout warning">
      <div class="callout-title">‚ö†Ô∏è Limitations of Symbolic AI</div>
      <p>
        While powerful for well-defined domains, symbolic AI struggles with:
      </p>
      <ul>
        <li><strong>Brittleness:</strong> Rules don't generalize beyond their specific domain</li>
        <li><strong>Knowledge Acquisition Bottleneck:</strong> Manually encoding expertise is time-consuming</li>
        <li><strong>Uncertainty:</strong> Real-world knowledge is often probabilistic, not absolute</li>
        <li><strong>Common Sense:</strong> Difficult to encode tacit human knowledge</li>
      </ul>
    </div>

    <h3>Statistical Learning</h3>
    
    <p>
      Beginning in the 1990s, AI shifted toward statistical and probabilistic methods. Instead of hand-coding 
      rules, systems learned patterns from data.
    </p>

    <pre class="mermaid" set:html={`graph LR
    A[Training Data] --> B[Learning Algorithm]
    B --> C[Statistical Model]
    C --> D[Predictions]
    E[New Data] --> C
    
    style A fill:#3b82f6,stroke:#2563eb,color:#fff
    style C fill:#8b5cf6,stroke:#7c3aed,color:#fff
    style D fill:#10b981,stroke:#059669,color:#fff
      `} />

    <h3>Connectionist AI (Neural Networks)</h3>
    
    <p>
      Inspired by biological neurons, neural networks learn by adjusting connection weights between simple 
      processing units. This approach became dominant with the deep learning revolution of the 2010s.
    </p>

    <h3>Hybrid Approaches</h3>
    
    <p>
      Modern AI often combines multiple paradigms. State-of-the-art systems in 2025 increasingly leverage hybrid architectures:
    </p>
    <ul>
      <li><strong>Neural-Symbolic Integration:</strong> Combining neural learning with logical reasoning (e.g., AlphaGeometry proving mathematical theorems)</li>
      <li><strong>Differentiable Programming:</strong> Making symbolic operations compatible with gradient descent (e.g., neural module networks)</li>
      <li><strong>Foundation Models + Tools:</strong> LLMs calling external knowledge bases, APIs, and specialized tools (e.g., ChatGPT with web browsing, code interpreter, DALL-E integration)</li>
      <li><strong>Retrieval-Augmented Generation (RAG):</strong> Neural models accessing structured knowledge bases (covered in Chapter 8)</li>
      <li><strong>Tree Search + Neural Networks:</strong> Combining classical search with learned heuristics (e.g., AlphaGo, AlphaZero, MuZero)</li>
      <li><strong>Neurosymbolic Reasoning:</strong> LLMs enhanced with formal verification, constraint solvers, and knowledge graphs</li>
    </ul>
    
    <div class="callout success">
      <div class="callout-title">‚ú® The Future is Hybrid</div>
      <p>
        The most powerful AI systems of the 2020s don't rely on a single approach. Instead, they combine the pattern 
        recognition capabilities of neural networks with the precision of symbolic reasoning, the efficiency of 
        algorithmic search, and the breadth of large-scale data. This "best of all worlds" strategy is likely to 
        dominate AI development through the 2030s.
      </p>
    </div>

    <h2>1.4 Search and Problem Solving</h2>

    <p>
      Many AI problems can be formulated as search: finding a path from an initial state to a goal state 
      through a space of possible states.
    </p>

    <h3>Search Space</h3>
    
    <div class="ascii-diagram">
                    Start
                     |
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           A         B         C
           |         |         |
        ‚îå‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îê
        D  E  F   G  H  I   J  K  L
                              |
                            GOAL
    </div>

    <h3>Uninformed Search Strategies</h3>

    <table>
      <thead>
        <tr>
          <th>Algorithm</th>
          <th>Strategy</th>
          <th>Complete</th>
          <th>Optimal</th>
          <th>Time/Space</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Breadth-First</td>
          <td>Expand shallowest</td>
          <td>Yes</td>
          <td>Yes</td>
          <td>O(b^d)</td>
        </tr>
        <tr>
          <td>Depth-First</td>
          <td>Expand deepest</td>
          <td>No</td>
          <td>No</td>
          <td>O(b*m)</td>
        </tr>
        <tr>
          <td>Uniform-Cost</td>
          <td>Expand lowest cost</td>
          <td>Yes</td>
          <td>Yes</td>
          <td>O(b^(C*/Œµ))</td>
        </tr>
      </tbody>
    </table>

    <h3>Informed Search (Heuristic Search)</h3>

    <p>
      Informed search uses domain knowledge to guide exploration toward promising areas of the search space.
    </p>

    <pre set:html={`<code>def a_star_search(start, goal, h_func):
    """A* search algorithm - Optimal pathfinding since 1968
    
    Still widely used in 2025 for robotics, game AI, route planning,
    and as a component in hybrid AI systems (e.g., combined with
    neural networks for learned heuristics).
    
    Args:
        start: Initial state
        goal: Goal state  
        h_func: Admissible heuristic function estimating cost to goal
    
    Returns:
        Optimal path from start to goal, or None if no path exists
    
    Time Complexity: O(b^d) worst case, but efficient with good heuristic
    Space Complexity: O(b^d) - stores all generated nodes
    Optimality: Guaranteed if h is admissible and consistent
    """
    frontier = PriorityQueue()
    frontier.put((0, start))
    came_from = {{start: None}}
    cost_so_far = {{start: 0}}
    
    while not frontier.empty():
        current = frontier.get()[1]
        
        if current == goal:
            return reconstruct_path(came_from, start, goal)
        
        for next_state in get_neighbors(current):
            new_cost = cost_so_far[current] + cost(current, next_state)
            
            if next_state not in cost_so_far or new_cost < cost_so_far[next_state]:
                cost_so_far[next_state] = new_cost
                # f(n) = g(n) + h(n): actual cost + estimated remaining
                priority = new_cost + h_func(next_state, goal)
                frontier.put((priority, next_state))
                came_from[next_state] = current
    
    return None  # No path found

# Modern extensions:
# - Anytime A*: Returns best solution found so far if interrupted
# - Weighted A*: Trades optimality for speed (f = g + w*h, w > 1)
# - Neural A*: Uses learned heuristics from deep networks
# - Hierarchical A*: Multi-level pathfinding for large spaces</code>`} />

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üîç Deep Dive: Heuristic Functions</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <p>
          A good heuristic function h(n) should be:
        </p>
        <ul>
          <li><strong>Admissible:</strong> Never overestimate the actual cost to reach the goal</li>
          <li><strong>Consistent:</strong> h(n) ‚â§ c(n,a,n') + h(n') for all states n, actions a</li>
          <li><strong>Informative:</strong> Provides meaningful guidance (not just h(n) = 0)</li>
        </ul>
        <p>Examples of heuristics:</p>
        <ul>
          <li><strong>Manhattan Distance:</strong> For grid-based movement</li>
          <li><strong>Euclidean Distance:</strong> For continuous space</li>
          <li><strong>Pattern Databases:</strong> Precomputed exact costs for subproblems</li>
        </ul>
      </div>
    </div>

    <h2>1.5 Knowledge Representation</h2>

    <p>
      How do we represent knowledge in a form that computers can process? Several frameworks exist:
    </p>

    <h3>Logic-Based Representations</h3>

    <pre set:html={`<code>% Prolog example: Family relationships
parent(tom, bob).
parent(tom, liz).
parent(bob, ann).
parent(bob, pat).
parent(pat, jim).

grandparent(X, Z) :- parent(X, Y), parent(Y, Z).
sibling(X, Y) :- parent(Z, X), parent(Z, Y), X \= Y.

% Query: ?- grandparent(tom, Who).
% Answer: Who = ann ; Who = pat</code>`} />

    <h3>Semantic Networks</h3>

    <pre class="mermaid" set:html={`graph TD
    A[Bird] -->|is-a| B[Animal]
    C[Penguin] -->|is-a| A
    D[Tweety] -->|instance-of| C
    A -->|can| E[Fly]
    A -->|has| F[Wings]
    C -->|cannot| E
    C -->|can| G[Swim]
    B -->|has| H[Metabolism]
    
    style B fill:#3b82f6
    style A fill:#8b5cf6
    style C fill:#ec4899
    style D fill:#10b981
      `} />

    <h3>Frames and Ontologies</h3>

    <p>
      Frames structure knowledge as objects with attributes (slots) and values:
    </p>

    <pre set:html={`<code>Person:
  is-a: Animal
  properties:
    - name: String
    - age: Integer
    - occupation: String
  methods:
    - introduce()
    - work()

Student:
  is-a: Person
  properties:
    - student_id: String
    - major: String
    - gpa: Float
  methods:
    - enroll(course)
    - study()</code>`} />

    <h2>1.6 Key Concepts Summary</h2>

    <div class="callout success">
      <div class="callout-title">‚úÖ Key Takeaways</div>
      <ul>
        <li>AI aims to create machines that exhibit intelligent behavior</li>
        <li>The field has evolved through symbolic, statistical, and connectionist paradigms</li>
        <li>Search algorithms are fundamental to problem-solving in AI</li>
        <li>Knowledge representation determines how systems store and reason with information</li>
        <li>Modern AI combines multiple approaches for robust, flexible systems</li>
      </ul>
    </div>

    <h2>Review Questions</h2>

    <div class="collapsible">
      <div class="collapsible-header">
        <span>‚ùì Test Your Understanding</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <ol>
          <li>What are the main differences between symbolic AI and connectionist AI?</li>
          <li>Why is the A* algorithm considered optimal if the heuristic is admissible?</li>
          <li>What caused the AI winters, and what lessons were learned?</li>
          <li>How do semantic networks differ from logical representations?</li>
          <li>What are the advantages and disadvantages of rule-based expert systems?</li>
        </ol>
      </div>
    </div>

    <h2>Practical Exercises</h2>

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üíª Hands-On Practice</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <ol>
          <li>
            <strong>Implement BFS and DFS:</strong> Write breadth-first and depth-first search algorithms 
            to solve a maze navigation problem.
          </li>
          <li>
            <strong>A* Pathfinding:</strong> Implement A* search with Manhattan distance heuristic for 
            grid-based navigation.
          </li>
          <li>
            <strong>Rule-Based System:</strong> Create a simple expert system for diagnosing computer 
            problems using if-then rules.
          </li>
          <li>
            <strong>Knowledge Base:</strong> Design an ontology for a domain of your choice (e.g., 
            movies, recipes, sports) using frames or semantic networks.
          </li>
        </ol>
      </div>
    </div>

    <div class="chapter-navigation">
      <a href="/" class="btn btn-secondary">‚Üê Home</a>
      <a href="/chapters/02-machine-learning" class="btn btn-primary">Next: Machine Learning ‚Üí</a>
    </div>
  </article>
</BaseLayout>

<style>
  .chapter-content {
    line-height: var(--line-height-relaxed);
  }
  
  .chapter-navigation {
    display: flex;
    justify-content: space-between;
    margin-top: var(--space-3xl);
    padding-top: var(--space-xl);
    border-top: 1px solid var(--color-border);
  }
  
  @media (max-width: 640px) {
    .chapter-navigation {
      flex-direction: column;
      gap: var(--space-md);
    }
  }
</style>
