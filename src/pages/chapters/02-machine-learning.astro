---
import BaseLayout from '../../layouts/BaseLayout.astro';
---

<BaseLayout 
  title="Chapter 2: Machine Learning" 
  description="Understanding supervised, unsupervised, and reinforcement learning fundamentals"
  currentPage="/chapters/02-machine-learning"
>
  <article class="chapter-content">
    <h1>Chapter 2: Machine Learning</h1>
    
    <div class="callout info">
      <div class="callout-title">üìö What You'll Learn</div>
      <ul>
        <li>Core machine learning paradigms and algorithms</li>
        <li>Supervised learning: classification and regression</li>
        <li>Unsupervised learning: clustering and dimensionality reduction</li>
        <li>Reinforcement learning fundamentals</li>
        <li>Model evaluation and validation techniques</li>
      </ul>
    </div>

    <h2>2.1 What is Machine Learning?</h2>
    
    <p>
      <strong>Machine Learning (ML)</strong> is a subset of AI focused on building systems that learn from 
      data. Rather than being explicitly programmed with rules, ML systems improve their performance through 
      experience. Modern ML (2023-2025) increasingly leverages <strong>foundation models</strong>, 
      <strong>transfer learning</strong>, and <strong>self-supervised learning</strong> to achieve unprecedented 
      capabilities across vision, language, and multimodal tasks.
    </p>

    <blockquote>
      "A computer program is said to learn from experience E with respect to some class of tasks T and 
      performance measure P, if its performance at tasks in T, as measured by P, improves with experience E." 
      ‚Äî Tom Mitchell
    </blockquote>

    <div class="callout info">
      <div class="callout-title">üöÄ Modern ML Landscape (2023-2025)</div>
      <ul>
        <li><strong>Foundation Models:</strong> Pre-trained transformers (GPT-4, Claude, Gemini) transfer knowledge across tasks</li>
        <li><strong>Self-Supervised Learning:</strong> Models learn representations from unlabeled data (e.g., BERT masking, contrastive learning)</li>
        <li><strong>AutoML:</strong> Automated hyperparameter tuning, neural architecture search, and feature engineering</li>
        <li><strong>Federated Learning:</strong> Train models across decentralized data without centralizing privacy-sensitive information</li>
        <li><strong>Few-Shot Learning:</strong> Models generalize from minimal examples using meta-learning techniques</li>
        <li><strong>Explainable AI (XAI):</strong> SHAP, LIME, attention visualization for model interpretability</li>
      </ul>
      <p><em>Source: Wikipedia Machine Learning article, November 2025</em></p>
    </div>

    <div class="diagram-container">
      <p class="diagram-title">Taxonomy of Machine Learning Approaches</p>
      <pre class="mermaid" role="img" aria-label="Hierarchical diagram showing machine learning divided into supervised, unsupervised, reinforcement, and semi-supervised learning, with their respective subcategories" set:html={`graph TD
    A[Machine Learning] --> B[Supervised Learning]
    A --> C[Unsupervised Learning]
    A --> D[Reinforcement Learning]
    A --> E[Semi-Supervised]
    
    B --> B1[Classification]
    B --> B2[Regression]
    
    C --> C1[Clustering]
    C --> C2[Dimensionality Reduction]
    C --> C3[Anomaly Detection]
    
    D --> D1[Model-Free]
    D --> D2[Model-Based]
    
    %% Semantic color classes
    classDef root fill:#dbeafe,stroke:#3b82f6,stroke-width:2px,color:#1e293b
    classDef supervised fill:#ede9fe,stroke:#8b5cf6,stroke-width:2px,color:#1e293b
    classDef unsupervised fill:#fce7f3,stroke:#ec4899,stroke-width:2px,color:#1e293b
    classDef reinforcement fill:#d1fae5,stroke:#10b981,stroke-width:2px,color:#1e293b
    classDef semi fill:#fef3c7,stroke:#f59e0b,stroke-width:2px,color:#1e293b
    classDef subtask fill:#f3f4f6,stroke:#6b7280,stroke-width:1.5px,color:#1e293b
    
    class A root
    class B,B1,B2 supervised
    class C,C1,C2,C3 unsupervised
    class D,D1,D2 reinforcement
    class E semi
      `} />
    </div>

    <h2>2.2 Supervised Learning</h2>

    <p>
      In supervised learning, we train models on labeled data‚Äîinput-output pairs where the correct answer 
      is known. The model learns to map inputs to outputs.
    </p>

    <h3>Classification</h3>
    
    <p>
      Classification assigns inputs to discrete categories. Examples include email spam detection, image 
      recognition, and medical diagnosis.
    </p>

    <pre set:html={`<code>from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import numpy as np

# Example: Binary classification
X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])
y = np.array([0, 0, 0, 1, 1, 1])  # Labels: 0 or 1

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)

# Train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
print(classification_report(y_test, y_pred))</code>`} />

    <h4>Popular Classification Algorithms</h4>

    <table>
      <thead>
        <tr>
          <th>Algorithm</th>
          <th>How It Works</th>
          <th>Strengths</th>
          <th>Limitations</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Logistic Regression</td>
          <td>Linear decision boundary with sigmoid activation</td>
          <td>Simple, interpretable, fast</td>
          <td>Assumes linear separability</td>
        </tr>
        <tr>
          <td>Decision Trees</td>
          <td>Hierarchical rules based on feature thresholds</td>
          <td>Interpretable, handles non-linear data</td>
          <td>Prone to overfitting</td>
        </tr>
        <tr>
          <td>Random Forest</td>
          <td>Ensemble of decision trees</td>
          <td>Robust, handles high dimensions</td>
          <td>Less interpretable, computationally expensive</td>
        </tr>
        <tr>
          <td>XGBoost/LightGBM</td>
          <td>Gradient boosting with optimized tree ensembles</td>
          <td>State-of-art tabular data, regularization built-in</td>
          <td>Requires careful tuning, black-box</td>
        </tr>
        <tr>
          <td>SVM</td>
          <td>Finds optimal hyperplane separating classes</td>
          <td>Effective in high dimensions</td>
          <td>Slow on large datasets</td>
        </tr>
        <tr>
          <td>k-NN</td>
          <td>Classifies based on k nearest neighbors</td>
          <td>Simple, no training phase</td>
          <td>Slow at inference, sensitive to scale</td>
        </tr>
        <tr>
          <td>Transformer Classifiers</td>
          <td>Self-attention mechanisms capture long-range dependencies</td>
          <td>SOTA for text/sequences, transfer learning via pre-training</td>
          <td>Computationally expensive, requires large data</td>
        </tr>
        <tr>
          <td>Vision Transformers (ViT)</td>
          <td>Apply transformers to image patches</td>
          <td>Surpass CNNs on large datasets (ImageNet >99% top-5)</td>
          <td>Needs substantial data/compute, less efficient than CNNs on small datasets</td>
        </tr>
      </tbody>
    </table>

    <div class="callout success">
      <div class="callout-title">üìä Modern Classification Benchmarks (2023-2025)</div>
      <ul>
        <li><strong>ImageNet (top-5 accuracy):</strong> Vision Transformers and CNNs now exceed 99% accuracy, surpassing human-level performance (~95%)</li>
        <li><strong>GLUE/SuperGLUE (NLP):</strong> Transformer models (GPT-4, Claude, Gemini) achieve near-perfect scores on many language understanding tasks</li>
        <li><strong>Kaggle Competitions:</strong> Gradient boosting (XGBoost, LightGBM) remains dominant for structured/tabular data</li>
        <li><strong>Zero-Shot Classification:</strong> CLIP, GPT-4V enable classification without task-specific training data</li>
      </ul>
      <p><em>Source: Wikipedia Deep Learning & Machine Learning articles, November 2025</em></p>
    </div>

    <h3>Regression</h3>
    
    <p>
      Regression predicts continuous values. Examples include house price prediction, stock forecasting, 
      and temperature estimation.
    </p>

    <pre set:html={`<code>from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Example: Linear regression
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 5, 4, 5])

model = LinearRegression()
model.fit(X, y)

# Predictions
X_new = np.array([[6], [7], [8]])
y_pred = model.predict(X_new)

print(f"Coefficient: {{model.coef_[0]:.2f}}")
print(f"Intercept: {{model.intercept_:.2f}}")
print(f"R¬≤ Score: {{model.score(X, y):.2f}}")</code>`} />

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üîç Deep Dive: Bias-Variance Tradeoff</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <p>
          Model error can be decomposed into three components:
        </p>
        <ul>
          <li><strong>Bias:</strong> Error from overly simplistic assumptions (underfitting)</li>
          <li><strong>Variance:</strong> Error from excessive sensitivity to training data (overfitting)</li>
          <li><strong>Irreducible Error:</strong> Noise in the data itself</li>
        </ul>
        <p>
          <code>Total Error = Bias¬≤ + Variance + Irreducible Error</code>
        </p>
        <p>
          The goal is to find the sweet spot that minimizes both bias and variance. Techniques include:
        </p>
        <ul>
          <li>Regularization (L1/L2)</li>
          <li>Cross-validation</li>
          <li>Ensemble methods</li>
          <li>Feature selection</li>
        </ul>
      </div>
    </div>

    <h2>2.3 Unsupervised Learning</h2>

    <p>
      Unsupervised learning finds patterns in data without labeled outputs. The system must discover 
      structure on its own. Modern approaches (2023-2025) leverage <strong>self-supervised learning</strong> 
      and <strong>contrastive methods</strong> to learn powerful representations from unlabeled data, powering 
      foundation models like BERT, GPT, and CLIP.
    </p>

    <div class="callout info">
      <div class="callout-title">üß† Modern Unsupervised Learning (2023-2025)</div>
      <ul>
        <li><strong>Self-Supervised Learning:</strong> Models predict missing/masked parts of data (e.g., BERT masked language modeling, MAE for images)</li>
        <li><strong>Contrastive Learning:</strong> SimCLR, MoCo learn by contrasting similar vs. dissimilar examples</li>
        <li><strong>Autoencoders:</strong> Variational autoencoders (VAEs) for generative modeling, denoising diffusion models</li>
        <li><strong>Representation Learning:</strong> Pre-train on massive unlabeled data, fine-tune on specific tasks</li>
        <li><strong>Anomaly Detection:</strong> Isolation forests, one-class SVMs, deep autoencoders for fraud detection, cybersecurity</li>
      </ul>
      <p><em>Source: Wikipedia Machine Learning article, November 2025</em></p>
    </div>

    <h3>Clustering</h3>
    
    <p>
      Clustering groups similar data points together. Applications include customer segmentation, document 
      organization, and anomaly detection.
    </p>

    <pre set:html={`<code>from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Example: K-Means clustering
X = np.array([[1, 2], [1.5, 1.8], [5, 8], [8, 8], [1, 0.6], [9, 11]])

kmeans = KMeans(n_clusters=2, random_state=0)
labels = kmeans.fit_predict(X)
centers = kmeans.cluster_centers_

print(f"Cluster labels: {{labels}}")
print(f"Cluster centers:\n{{centers}}")
print(f"Inertia (within-cluster sum of squares): {{kmeans.inertia_:.2f}}")</code>`} />

    <div class="diagram-container">
      <p class="diagram-title">Clustering Process: Grouping Unlabeled Data</p>
      <pre class="mermaid" role="img" aria-label="Flow diagram showing how unlabeled data is processed by a clustering algorithm using similarity measures to form three distinct clusters" set:html={`graph LR
    A[Unlabeled Data] --> B[Clustering Algorithm]
    B --> C{Similarity Measure}
    C -->|Similar Items| D[Cluster 1]
    C -->|Similar Items| E[Cluster 2]
    C -->|Similar Items| F[Cluster 3]
    
    %% Semantic color classes
    classDef input fill:#dbeafe,stroke:#3b82f6,stroke-width:2px,color:#1e293b
    classDef process fill:#ede9fe,stroke:#8b5cf6,stroke-width:2px,color:#1e293b
    classDef decision fill:#f3f4f6,stroke:#6b7280,stroke-width:2px,color:#1e293b,stroke-dasharray: 5 5
    classDef output fill:#d1fae5,stroke:#10b981,stroke-width:2px,color:#1e293b
    
    class A input
    class B process
    class C decision
    class D,E,F output
      `} />
    </div>

    <h4>Common Clustering Algorithms</h4>

    <ul>
      <li><strong>K-Means:</strong> Partitions data into k clusters by minimizing within-cluster variance</li>
      <li><strong>DBSCAN:</strong> Density-based clustering that can find arbitrary-shaped clusters</li>
      <li><strong>Hierarchical:</strong> Builds a tree of clusters through agglomerative or divisive methods</li>
      <li><strong>Gaussian Mixture Models:</strong> Probabilistic model assuming data comes from mixture of Gaussians</li>
    </ul>

    <h3>Dimensionality Reduction</h3>
    
    <p>
      Dimensionality reduction transforms high-dimensional data into lower dimensions while preserving 
      important structure.
    </p>

    <pre set:html={`<code>from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# Example: PCA for dimensionality reduction
X = np.random.rand(100, 50)  # 100 samples, 50 features

# Reduce to 2 dimensions
pca = PCA(n_components=2)
X_reduced = pca.fit_transform(X)

print(f"Original shape: {{X.shape}}")
print(f"Reduced shape: {{X_reduced.shape}}")
print(f"Explained variance ratio: {{pca.explained_variance_ratio_}}")</code>`} />

    <h2>2.4 Reinforcement Learning</h2>

    <p>
      Reinforcement Learning (RL) trains agents to make sequences of decisions by rewarding desired behaviors 
      and punishing undesired ones. The agent learns a policy‚Äîa mapping from states to actions‚Äîthat maximizes 
      cumulative reward. Modern RL (2023-2025) combines deep neural networks with RL algorithms (<strong>Deep RL</strong>) 
      to achieve superhuman performance in complex domains like games (AlphaGo, AlphaZero, OpenAI Five), robotics, 
      and autonomous systems.
    </p>

    <div class="callout success">
      <div class="callout-title">üéÆ Modern RL Achievements (2023-2025)</div>
      <ul>
        <li><strong>AlphaZero (2017):</strong> Mastered chess, shogi, and Go through self-play RL without human knowledge</li>
        <li><strong>AlphaFold 2 (2020):</strong> Solved protein folding using RL + structure prediction (2024 Nobel Prize in Chemistry)</li>
        <li><strong>RLHF (2023-2025):</strong> Reinforcement Learning from Human Feedback trains LLMs (ChatGPT, Claude) to align with human preferences</li>
        <li><strong>Robotics:</strong> Deep TAMER (U.S. Army, 2018), Covariant.ai (2017) use RL for real-world robot control</li>
        <li><strong>Autonomous Vehicles:</strong> RL optimizes decision-making for Tesla FSD, Waymo, Cruise</li>
        <li><strong>Game AI:</strong> OpenAI Five (Dota 2), MuZero (learned game rules from scratch), Agent57 (first superhuman Atari agent)</li>
      </ul>
      <p><em>Source: Wikipedia Deep Learning & Machine Learning articles, November 2025</em></p>
    </div>

    <div class="diagram-container">
      <p class="diagram-title">Reinforcement Learning Loop</p>
      <pre class="mermaid" role="img" aria-label="Reinforcement learning feedback loop showing environment sending state and reward to agent, agent taking actions, and updating its policy" set:html={`graph LR
    A[Environment] -->|State s, Reward r| B[Agent]
    B -->|Action a| A
    B -.->|Learn| C[Policy œÄ]
    C -.->|Guide Decisions| B
    
    %% Semantic color classes
    classDef environment fill:#dbeafe,stroke:#3b82f6,stroke-width:2px,color:#1e293b
    classDef agent fill:#ede9fe,stroke:#8b5cf6,stroke-width:2px,color:#1e293b
    classDef policy fill:#fce7f3,stroke:#ec4899,stroke-width:2px,color:#1e293b
    
    class A environment
    class B agent
    class C policy
      `} />
      <p class="diagram-caption"><em>The agent observes states and rewards, takes actions, and continuously updates its policy to maximize cumulative reward</em></p>
    </div>

    <h3>Key Concepts</h3>

    <ul>
      <li><strong>State (s):</strong> Current situation of the agent</li>
      <li><strong>Action (a):</strong> Decision made by the agent</li>
      <li><strong>Reward (r):</strong> Feedback signal from environment</li>
      <li><strong>Policy (œÄ):</strong> Strategy for selecting actions</li>
      <li><strong>Value Function (V):</strong> Expected cumulative reward from a state</li>
      <li><strong>Q-Function (Q):</strong> Expected reward from taking action a in state s</li>
    </ul>

    <h3>Q-Learning Example</h3>

    <pre set:html={`<code>import numpy as np

class QLearningAgent:
    def __init__(self, n_states, n_actions, learning_rate=0.1, gamma=0.95, epsilon=0.1):
        self.q_table = np.zeros((n_states, n_actions))
        self.lr = learning_rate
        self.gamma = gamma  # Discount factor
        self.epsilon = epsilon  # Exploration rate
        
    def choose_action(self, state):
        """Epsilon-greedy action selection"""
        if np.random.random() < self.epsilon:
            return np.random.randint(len(self.q_table[state]))  # Explore
        return np.argmax(self.q_table[state])  # Exploit
    
    def update(self, state, action, reward, next_state):
        """Q-learning update rule"""
        current_q = self.q_table[state, action]
        max_next_q = np.max(self.q_table[next_state])
        new_q = current_q + self.lr * (reward + self.gamma * max_next_q - current_q)
        self.q_table[state, action] = new_q

# Training loop (pseudocode)
agent = QLearningAgent(n_states=100, n_actions=4)
for episode in range(1000):
    state = env.reset()
    done = False
    while not done:
        action = agent.choose_action(state)
        next_state, reward, done = env.step(action)
        agent.update(state, action, reward, next_state)
        state = next_state</code>`} />

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üîç Deep Dive: Model-Free vs Model-Based RL</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <h4>Model-Free RL (Deep RL Era)</h4>
        <p>
          Learns directly from experience without building an explicit model of the environment.
        </p>
        <ul>
          <li><strong>Q-Learning (DQN):</strong> Deep Q-Networks use neural nets to approximate Q-function (Atari breakthrough, 2013)</li>
          <li><strong>SARSA:</strong> On-policy TD learning</li>
          <li><strong>Policy Gradient (PPO, A3C):</strong> Proximal Policy Optimization (PPO) is widely used for robotics, games</li>
          <li><strong>Actor-Critic (SAC, TD3):</strong> Soft Actor-Critic (SAC) achieves state-of-art continuous control</li>
          <li><strong>Rainbow DQN:</strong> Combines multiple DQN improvements for superior Atari performance</li>
          <li><strong>RLHF (2023-2025):</strong> Fine-tunes LLMs using human feedback for alignment (ChatGPT, Claude, Gemini)</li>
        </ul>
        
        <h4>Model-Based RL (Planning + Learning)</h4>
        <p>
          Builds a model of environment dynamics, then uses it for planning. More sample-efficient than model-free.
        </p>
        <ul>
          <li><strong>Dyna-Q:</strong> Combines learning and planning by generating simulated experience</li>
          <li><strong>AlphaGo/AlphaZero (2016-2017):</strong> Monte Carlo Tree Search with learned value/policy nets, mastered Go/Chess/Shogi</li>
          <li><strong>MuZero (2019):</strong> Learns latent environment model without knowing true dynamics, plans in learned representation space</li>
          <li><strong>Dreamer (2020-2023):</strong> World models for visual RL, achieves sample-efficient control from pixels</li>
          <li><strong>Deep TAMER (2018):</strong> Learns from human demonstrations and evaluative feedback for robotics</li>
        </ul>
        
        <p><strong>Key Tradeoff:</strong> Model-free is simpler but requires more data; model-based is sample-efficient but requires accurate environment models.</p>
      </div>
    </div>

    <h2>2.5 Model Evaluation & Validation</h2>

    <h3>Train-Test Split</h3>
    
    <p>
      Never evaluate on training data! Split data into training and test sets to estimate generalization.
    </p>

    <pre set:html={`<code>from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20% for testing
    random_state=42,    # Reproducibility
    stratify=y          # Maintain class distribution
)</code>`} />

    <h3>Cross-Validation</h3>
    
    <p>
      More robust evaluation by training on multiple train/test splits.
    </p>

    <pre set:html={`<code>from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)  # 5-fold CV
print(f"Scores: {{scores}}")
print(f"Mean: {{scores.mean():.3f}} (+/- {{scores.std() * 2:.3f}})")</code>`} />

    <h3>Metrics</h3>

    <table>
      <thead>
        <tr>
          <th>Task</th>
          <th>Metric</th>
          <th>Description</th>
          <th>When to Use</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td rowspan="5">Classification</td>
          <td>Accuracy</td>
          <td>% correct predictions</td>
          <td>Balanced classes</td>
        </tr>
        <tr>
          <td>Precision</td>
          <td>TP / (TP + FP)</td>
          <td>Minimize false positives</td>
        </tr>
        <tr>
          <td>Recall</td>
          <td>TP / (TP + FN)</td>
          <td>Minimize false negatives</td>
        </tr>
        <tr>
          <td>F1 Score</td>
          <td>Harmonic mean of P & R</td>
          <td>Balance P and R</td>
        </tr>
        <tr>
          <td>AUC-ROC</td>
          <td>Area under ROC curve</td>
          <td>Compare models across thresholds, imbalanced classes</td>
        </tr>
        <tr>
          <td rowspan="4">Regression</td>
          <td>MAE</td>
          <td>Mean absolute error</td>
          <td>Interpretable, robust to outliers</td>
        </tr>
        <tr>
          <td>MSE</td>
          <td>Mean squared error</td>
          <td>Penalizes large errors</td>
        </tr>
        <tr>
          <td>RMSE</td>
          <td>Root mean squared error</td>
          <td>Same units as target, common in Kaggle</td>
        </tr>
        <tr>
          <td>R¬≤</td>
          <td>Proportion of variance explained</td>
          <td>Model goodness-of-fit</td>
        </tr>
      </tbody>
    </table>

    <div class="callout info">
      <div class="callout-title">üõ†Ô∏è Modern ML Tools & Frameworks (2023-2025)</div>
      <ul>
        <li><strong>PyTorch & TensorFlow:</strong> Dominant deep learning frameworks with automatic differentiation</li>
        <li><strong>JAX:</strong> Google's high-performance ML library with composable transformations (grad, jit, vmap)</li>
        <li><strong>scikit-learn:</strong> Standard library for classical ML algorithms (classification, regression, clustering)</li>
        <li><strong>Hugging Face Transformers:</strong> Pre-trained models (BERT, GPT, T5) with easy fine-tuning APIs</li>
        <li><strong>XGBoost/LightGBM:</strong> Gradient boosting libraries dominating Kaggle competitions for tabular data</li>
        <li><strong>Ray/Tune:</strong> Distributed hyperparameter tuning and model training</li>
        <li><strong>MLflow/Weights & Biases:</strong> Experiment tracking, model versioning, deployment</li>
        <li><strong>AutoML (AutoGluon, H2O.ai):</strong> Automated model selection, hyperparameter tuning, feature engineering</li>
      </ul>
      <p><em>Source: Wikipedia Machine Learning & Deep Learning articles, November 2025</em></p>
    </div>

    <h2>2.6 Key Concepts Summary</h2>

    <div class="callout success">
      <div class="callout-title">‚úÖ Key Takeaways</div>
      <ul>
        <li>Machine learning enables systems to learn from data without explicit programming</li>
        <li>Supervised learning requires labeled data; unsupervised finds patterns autonomously</li>
        <li>Reinforcement learning optimizes sequential decision-making through trial and error</li>
        <li><strong>Modern ML (2023-2025):</strong> Foundation models, self-supervised learning, and transfer learning dominate</li>
        <li><strong>Transformers:</strong> Surpass traditional algorithms for NLP, vision (ViT >99% ImageNet), and multimodal tasks</li>
        <li><strong>Deep RL:</strong> Powers AlphaZero game mastery, AlphaFold protein folding (2024 Nobel), RLHF for LLM alignment</li>
        <li><strong>AutoML & Tools:</strong> PyTorch, TensorFlow, JAX, Hugging Face, XGBoost simplify modern ML workflows</li>
        <li>Proper evaluation requires train-test splits, cross-validation, and task-appropriate metrics (accuracy, AUC-ROC, F1, RMSE)</li>
      </ul>
      <p><em>Source: Wikipedia Machine Learning & Deep Learning articles, November 2025</em></p>
    </div>

    <h2>Review Questions</h2>

    <div class="collapsible">
      <div class="collapsible-header">
        <span>‚ùì Test Your Understanding</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <ol>
          <li>What's the difference between classification and regression?</li>
          <li>When would you use unsupervised learning instead of supervised learning?</li>
          <li>Explain the exploration-exploitation tradeoff in reinforcement learning.</li>
          <li>Why is accuracy not always the best metric for classification?</li>
          <li>What is the bias-variance tradeoff?</li>
        </ol>
      </div>
    </div>

    <h2>Practical Exercises</h2>

    <div class="collapsible">
      <div class="collapsible-header">
        <span>üíª Hands-On Practice</span>
        <span class="collapsible-icon">‚ñº</span>
      </div>
      <div class="collapsible-content">
        <ol>
          <li>
            <strong>Classification:</strong> Build a spam detector using logistic regression on email text features.
          </li>
          <li>
            <strong>Regression:</strong> Predict house prices using multiple features (size, location, bedrooms).
          </li>
          <li>
            <strong>Clustering:</strong> Segment customers based on purchasing behavior using k-means.
          </li>
          <li>
            <strong>RL Agent:</strong> Implement a Q-learning agent to solve a simple grid-world navigation task.
          </li>
          <li>
            <strong>Model Comparison:</strong> Compare decision trees, random forests, and SVM on a benchmark dataset.
          </li>
        </ol>
      </div>
    </div>

    <div class="chapter-navigation">
      <a href="/chapters/01-foundations" class="btn btn-secondary">‚Üê Foundations</a>
      <a href="/chapters/03-deep-learning" class="btn btn-primary">Next: Deep Learning ‚Üí</a>
    </div>
  </article>
</BaseLayout>

<style>
  .chapter-content {
    line-height: var(--line-height-relaxed);
  }
  
  .chapter-navigation {
    display: flex;
    justify-content: space-between;
    margin-top: var(--space-3xl);
    padding-top: var(--space-xl);
    border-top: 1px solid var(--color-border);
  }
  
  @media (max-width: 640px) {
    .chapter-navigation {
      flex-direction: column;
      gap: var(--space-md);
    }
  }
</style>
